---
title: Reducing classifier overconfidence against adversaries through graph algorithms
authors:
- Leonardo Teixeira
- Brian Jalaian
- Bruno Ribeiro
date: '2023-07-01'
publishDate: '2024-10-06T03:28:00.725092Z'
publication_types:
- article-journal
publication: '*Machine Learning*'
doi: 10.1007/s10994-023-06307-y
abstract: In this work we show that deep learning classifiers tend to become overconfident
  in their answers under adversarial attacks, even when the classifier is optimized
  to survive such attacks. Our work draws upon stochastic geometry and graph algorithms
  to propose a general framework to replace the last fully connected layer and softmax
  output. This framework (a) can be applied to any classifier and (b) significantly
  reduces the classifierâ€™s overconfidence in its output without much of an impact
  on its accuracy when compared to original adversarially-trained classifiers. Its
  relative effectiveness increases as the attacker becomes more powerful. Our use
  of graph algorithms in adversarial learning is new and of independent interest.
  Finally, we show the advantages of this last-layer softmax replacement over image
  tasks under common adversarial attacks.
tags:
- Adversarial robustness
- Gossip algorithm
- Overconfidence
links:
- name: URL
  url: https://doi.org/10.1007/s10994-023-06307-y
---
