---
title: Assessing the Adversarial Robustness of Monte Carlo and Distillation Methods
  for Deep Bayesian Neural Network Classification
authors:
- Meet P Vadera
- Satya Narayan Shukla
- Brian Jalaian
- Benjamin M Marlin
- Satya Narayan Shukla
- Brian Jalaian
- Benjamin M Marlin
date: '2020-01-01'
publishDate: '2024-10-06T03:28:00.617235Z'
publication_types:
- article-journal
publication: '*arXiv preprint arXiv:2002.02842*'
abstract: 'In this paper, we consider the problem of assessing the ad-versarial robustness
  of deep neural network models under both Markov chain Monte Carlo (MCMC) and Bayesian
  Dark Knowledge (BDK) inference approximations. We characterize the robustness of
  each method to two types of adversarial attacks: the fast gradient sign method (FGSM)
  and projected gradient descent (PGD). We show that full MCMC-based inference has
  excellent robustness, significantly outperforming standard point estimation-based
  learning. On the other hand, BDK provides marginal improvements. As an additional
  contribution , we present a storage-efficient approach to computing adversarial
  examples for large Monte Carlo ensembles using both the FGSM and PGD attacks.'
---
